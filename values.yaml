NAME: airflow
LAST DEPLOYED: Sun Dec 17 14:36:31 2023
NAMESPACE: airflow
STATUS: deployed
REVISION: 10
CHART: airflow
VERSION: 1.11.0
APP_VERSION: 2.7.1
TEST SUITE: None
USER-SUPPLIED VALUES:
dags:
  persistence:
    enabled: true
    existingClaim: airflow-dags
    storageClassName: local-storage
env:
- name: OPENLINEAGE_NAMESPACE
  value: airflow
extraPipPackages:
- openlineage-airflow==1.6.2

COMPUTED VALUES:
affinity: {}
airflowConfigAnnotations: {}
airflowHome: /opt/airflow
airflowLocalSettings: |-
  {{- if semverCompare ">=2.2.0" .Values.airflowVersion }}
  {{- if not (or .Values.webserverSecretKey .Values.webserverSecretKeySecretName) }}
  from airflow.www.utils import UIAlert

  DASHBOARD_UIALERTS = [
    UIAlert(
      'Usage of a dynamic webserver secret key detected. We recommend a static webserver secret key instead.'
      ' See the <a href='
      '"https://airflow.apache.org/docs/helm-chart/stable/production-guide.html#webserver-secret-key">'
      'Helm Chart Production Guide</a> for more details.',
      category="warning",
      roles=["Admin"],
      html=True,
    )
  ]
  {{- end }}
  {{- end }}
airflowPodAnnotations: {}
airflowVersion: 2.7.1
allowPodLaunching: true
cleanup:
  affinity: {}
  args:
  - bash
  - -c
  - exec airflow kubernetes cleanup-pods --namespace={{ .Release.Namespace }}
  command: null
  containerLifecycleHooks: {}
  enabled: false
  env: []
  failedJobsHistoryLimit: null
  jobAnnotations: {}
  labels: {}
  nodeSelector: {}
  podAnnotations: {}
  resources: {}
  schedule: '*/15 * * * *'
  securityContext: {}
  securityContexts:
    container: {}
    pod: {}
  serviceAccount:
    annotations: {}
    automountServiceAccountToken: true
    create: true
    name: null
  successfulJobsHistoryLimit: null
  tolerations: []
  topologySpreadConstraints: []
config:
  celery:
    flower_url_prefix: '{{ ternary "" .Values.ingress.flower.path (eq .Values.ingress.flower.path
      "/") }}'
    worker_concurrency: 16
  celery_kubernetes_executor:
    kubernetes_queue: kubernetes
  core:
    colored_console_log: "False"
    dags_folder: '{{ include "airflow_dags" . }}'
    executor: '{{ .Values.executor }}'
    load_examples: "False"
    remote_logging: '{{- ternary "True" "False" .Values.elasticsearch.enabled }}'
  elasticsearch:
    json_format: "True"
    log_id_template: '{dag_id}_{task_id}_{execution_date}_{try_number}'
  elasticsearch_configs:
    max_retries: 3
    retry_timeout: "True"
    timeout: 30
  kerberos:
    ccache: '{{ .Values.kerberos.ccacheMountPath }}/{{ .Values.kerberos.ccacheFileName
      }}'
    keytab: '{{ .Values.kerberos.keytabPath }}'
    principal: '{{ .Values.kerberos.principal }}'
    reinit_frequency: '{{ .Values.kerberos.reinitFrequency }}'
  kubernetes:
    airflow_configmap: '{{ include "airflow_config" . }}'
    airflow_local_settings_configmap: '{{ include "airflow_config" . }}'
    multi_namespace_mode: '{{ ternary "True" "False" .Values.multiNamespaceMode }}'
    namespace: '{{ .Release.Namespace }}'
    pod_template_file: '{{ include "airflow_pod_template_file" . }}/pod_template_file.yaml'
    worker_container_repository: '{{ .Values.images.airflow.repository | default .Values.defaultAirflowRepository
      }}'
    worker_container_tag: '{{ .Values.images.airflow.tag | default .Values.defaultAirflowTag
      }}'
  kubernetes_executor:
    multi_namespace_mode: '{{ ternary "True" "False" .Values.multiNamespaceMode }}'
    namespace: '{{ .Release.Namespace }}'
    pod_template_file: '{{ include "airflow_pod_template_file" . }}/pod_template_file.yaml'
    worker_container_repository: '{{ .Values.images.airflow.repository | default .Values.defaultAirflowRepository
      }}'
    worker_container_tag: '{{ .Values.images.airflow.tag | default .Values.defaultAirflowTag
      }}'
  logging:
    colored_console_log: "False"
    remote_logging: '{{- ternary "True" "False" .Values.elasticsearch.enabled }}'
  metrics:
    statsd_host: '{{ printf "%s-statsd" .Release.Name }}'
    statsd_on: '{{ ternary "True" "False" .Values.statsd.enabled }}'
    statsd_port: 9125
    statsd_prefix: airflow
  scheduler:
    run_duration: 41460
    standalone_dag_processor: '{{ ternary "True" "False" .Values.dagProcessor.enabled
      }}'
    statsd_host: '{{ printf "%s-statsd" .Release.Name }}'
    statsd_on: '{{ ternary "True" "False" .Values.statsd.enabled }}'
    statsd_port: 9125
    statsd_prefix: airflow
  triggerer:
    default_capacity: 1000
  webserver:
    enable_proxy_fix: "True"
    rbac: "True"
containerLifecycleHooks: {}
createUserJob:
  affinity: {}
  annotations: {}
  applyCustomEnv: true
  args:
  - bash
  - -c
  - |-
    exec \
    airflow {{ semverCompare ">=2.0.0" .Values.airflowVersion | ternary "users create" "create_user" }} "$@"
  - --
  - -r
  - '{{ .Values.webserver.defaultUser.role }}'
  - -u
  - '{{ .Values.webserver.defaultUser.username }}'
  - -e
  - '{{ .Values.webserver.defaultUser.email }}'
  - -f
  - '{{ .Values.webserver.defaultUser.firstName }}'
  - -l
  - '{{ .Values.webserver.defaultUser.lastName }}'
  - -p
  - '{{ .Values.webserver.defaultUser.password }}'
  command: null
  containerLifecycleHooks: {}
  env: []
  extraContainers: []
  extraVolumeMounts: []
  extraVolumes: []
  jobAnnotations: {}
  labels: {}
  nodeSelector: {}
  resources: {}
  securityContext: {}
  securityContexts:
    container: {}
    pod: {}
  serviceAccount:
    annotations: {}
    automountServiceAccountToken: true
    create: true
    name: null
  tolerations: []
  topologySpreadConstraints: []
  ttlSecondsAfterFinished: 300
  useHelmHooks: true
dagProcessor:
  affinity: {}
  annotations: {}
  args:
  - bash
  - -c
  - exec airflow dag-processor
  command: null
  containerLifecycleHooks: {}
  enabled: false
  env: []
  extraContainers: []
  extraInitContainers: []
  extraVolumeMounts: []
  extraVolumes: []
  livenessProbe:
    command: null
    failureThreshold: 5
    initialDelaySeconds: 10
    periodSeconds: 60
    timeoutSeconds: 20
  logGroomerSidecar:
    args:
    - bash
    - /clean-logs
    command: null
    enabled: true
    resources: {}
    retentionDays: 15
  nodeSelector: {}
  podAnnotations: {}
  priorityClassName: null
  replicas: 1
  resources: {}
  revisionHistoryLimit: null
  safeToEvict: true
  securityContext: {}
  securityContexts:
    container: {}
    pod: {}
  serviceAccount:
    annotations: {}
    automountServiceAccountToken: true
    create: true
    name: null
  strategy:
    rollingUpdate:
      maxSurge: 100%
      maxUnavailable: 50%
  terminationGracePeriodSeconds: 60
  tolerations: []
  topologySpreadConstraints: []
  waitForMigrations:
    enabled: true
    env: []
dags:
  gitSync:
    branch: v2-2-stable
    containerLifecycleHooks: {}
    containerName: git-sync
    depth: 1
    enabled: false
    env: []
    extraVolumeMounts: []
    maxFailures: 0
    repo: https://github.com/apache/airflow.git
    resources: {}
    rev: HEAD
    securityContext: {}
    securityContexts:
      container: {}
    subPath: tests/dags
    uid: 65533
    wait: 5
  persistence:
    accessMode: ReadWriteOnce
    annotations: {}
    enabled: true
    existingClaim: airflow-dags
    size: 1Gi
    storageClassName: local-storage
    subPath: null
data:
  brokerUrl: null
  brokerUrlSecretName: null
  metadataConnection:
    db: postgres
    host: null
    pass: postgres
    port: 5432
    protocol: postgresql
    sslmode: disable
    user: postgres
  metadataSecretName: null
  resultBackendConnection: null
  resultBackendSecretName: null
defaultAirflowDigest: null
defaultAirflowRepository: apache/airflow
defaultAirflowTag: 2.7.1
elasticsearch:
  connection: {}
  enabled: false
  secretName: null
enableBuiltInSecretEnvVars:
  AIRFLOW__CELERY__BROKER_URL: true
  AIRFLOW__CELERY__CELERY_RESULT_BACKEND: true
  AIRFLOW__CELERY__RESULT_BACKEND: true
  AIRFLOW__CORE__FERNET_KEY: true
  AIRFLOW__CORE__SQL_ALCHEMY_CONN: true
  AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: true
  AIRFLOW__ELASTICSEARCH__ELASTICSEARCH_HOST: true
  AIRFLOW__ELASTICSEARCH__HOST: true
  AIRFLOW__WEBSERVER__SECRET_KEY: true
  AIRFLOW_CONN_AIRFLOW_DB: true
env:
- name: OPENLINEAGE_NAMESPACE
  value: airflow
executor: CeleryExecutor
extraConfigMaps: {}
extraEnv: null
extraEnvFrom: null
extraPipPackages:
- openlineage-airflow==1.6.2
extraSecrets: {}
fernetKey: null
fernetKeySecretName: null
flower:
  affinity: {}
  annotations: {}
  args:
  - bash
  - -c
  - |-
    exec \
    airflow {{ semverCompare ">=2.0.0" .Values.airflowVersion | ternary "celery flower" "flower" }}
  command: null
  containerLifecycleHooks: {}
  enabled: false
  env: []
  extraContainers: []
  extraNetworkPolicies: []
  extraVolumeMounts: []
  extraVolumes: []
  labels: {}
  networkPolicy:
    ingress:
      from: []
      ports:
      - port: '{{ .Values.ports.flowerUI }}'
  nodeSelector: {}
  password: null
  podAnnotations: {}
  priorityClassName: null
  resources: {}
  revisionHistoryLimit: null
  secretName: null
  securityContext: {}
  securityContexts:
    container: {}
    pod: {}
  service:
    annotations: {}
    loadBalancerIP: null
    loadBalancerSourceRanges: []
    ports:
    - name: flower-ui
      port: '{{ .Values.ports.flowerUI }}'
    type: ClusterIP
  serviceAccount:
    annotations: {}
    automountServiceAccountToken: true
    create: true
    name: null
  tolerations: []
  topologySpreadConstraints: []
  username: null
fullnameOverride: ""
gid: 0
images:
  airflow:
    digest: null
    pullPolicy: IfNotPresent
    repository: null
    tag: null
  flower:
    pullPolicy: IfNotPresent
    repository: null
    tag: null
  gitSync:
    pullPolicy: IfNotPresent
    repository: registry.k8s.io/git-sync/git-sync
    tag: v3.6.9
  migrationsWaitTimeout: 60
  pgbouncer:
    pullPolicy: IfNotPresent
    repository: apache/airflow
    tag: airflow-pgbouncer-2023.02.24-1.16.1
  pgbouncerExporter:
    pullPolicy: IfNotPresent
    repository: apache/airflow
    tag: airflow-pgbouncer-exporter-2023.02.21-0.14.0
  pod_template:
    pullPolicy: IfNotPresent
    repository: null
    tag: null
  redis:
    pullPolicy: IfNotPresent
    repository: redis
    tag: 7-bullseye
  statsd:
    pullPolicy: IfNotPresent
    repository: quay.io/prometheus/statsd-exporter
    tag: v0.22.8
  useDefaultImageForMigration: false
ingress:
  enabled: null
  flower:
    annotations: {}
    enabled: false
    host: ""
    hosts: []
    ingressClassName: ""
    path: /
    pathType: ImplementationSpecific
    tls:
      enabled: false
      secretName: ""
  web:
    annotations: {}
    enabled: false
    host: ""
    hosts: []
    ingressClassName: ""
    path: /
    pathType: ImplementationSpecific
    precedingPaths: []
    succeedingPaths: []
    tls:
      enabled: false
      secretName: ""
kerberos:
  ccacheFileName: cache
  ccacheMountPath: /var/kerberos-ccache
  config: |
    # This is an example config showing how you can use templating and how "example" config
    # might look like. It works with the test kerberos server that we are using during integration
    # testing at Apache Airflow (see `scripts/ci/docker-compose/integration-kerberos.yml` but in
    # order to make it production-ready you must replace it with your own configuration that
    # Matches your kerberos deployment. Administrators of your Kerberos instance should
    # provide the right configuration.

    [logging]
    default = "FILE:{{ template "airflow_logs_no_quote" . }}/kerberos_libs.log"
    kdc = "FILE:{{ template "airflow_logs_no_quote" . }}/kerberos_kdc.log"
    admin_server = "FILE:{{ template "airflow_logs_no_quote" . }}/kadmind.log"

    [libdefaults]
    default_realm = FOO.COM
    ticket_lifetime = 10h
    renew_lifetime = 7d
    forwardable = true

    [realms]
    FOO.COM = {
      kdc = kdc-server.foo.com
      admin_server = admin_server.foo.com
    }
  configPath: /etc/krb5.conf
  enabled: false
  keytabBase64Content: null
  keytabPath: /etc/airflow.keytab
  principal: airflow@FOO.COM
  reinitFrequency: 3600
labels: {}
limits: []
logs:
  persistence:
    annotations: {}
    enabled: false
    existingClaim: null
    size: 100Gi
    storageClassName: null
migrateDatabaseJob:
  affinity: {}
  annotations: {}
  applyCustomEnv: true
  args:
  - bash
  - -c
  - |-
    exec \
    airflow {{ semverCompare ">=2.7.0" .Values.airflowVersion | ternary "db migrate" (semverCompare ">=2.0.0" .Values.airflowVersion | ternary "db upgrade" "upgradedb") }}
  command: null
  containerLifecycleHooks: {}
  enabled: true
  extraContainers: []
  extraVolumeMounts: []
  extraVolumes: []
  jobAnnotations: {}
  nodeSelector: {}
  resources: {}
  securityContext: {}
  securityContexts:
    container: {}
    pod: {}
  serviceAccount:
    annotations: {}
    automountServiceAccountToken: true
    create: true
    name: null
  tolerations: []
  topologySpreadConstraints: []
  ttlSecondsAfterFinished: 300
  useHelmHooks: true
multiNamespaceMode: false
nameOverride: ""
networkPolicies:
  enabled: false
nodeSelector: {}
pgbouncer:
  affinity: {}
  annotations: {}
  args: null
  auth_file: /etc/pgbouncer/users.txt
  auth_type: md5
  ciphers: normal
  command:
  - pgbouncer
  - -u
  - nobody
  - /etc/pgbouncer/pgbouncer.ini
  configSecretName: null
  containerLifecycleHooks:
    preStop:
      exec:
        command:
        - /bin/sh
        - -c
        - killall -INT pgbouncer && sleep 120
  enabled: false
  env: []
  extraContainers: []
  extraIni: null
  extraIniMetadata: null
  extraIniResultBackend: null
  extraNetworkPolicies: []
  extraVolumeMounts: []
  extraVolumes: []
  logConnections: 0
  logDisconnections: 0
  maxClientConn: 100
  metadataPoolSize: 10
  metricsExporterSidecar:
    containerLifecycleHooks: {}
    livenessProbe:
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 1
    readinessProbe:
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 1
    resources: {}
    securityContexts:
      container: {}
    sslmode: disable
    statsSecretKey: null
    statsSecretName: null
  nodeSelector: {}
  podAnnotations: {}
  podDisruptionBudget:
    config:
      maxUnavailable: 1
    enabled: false
  priorityClassName: null
  replicas: 1
  resources: {}
  resultBackendPoolSize: 5
  revisionHistoryLimit: null
  securityContexts:
    container: {}
    pod: {}
  service:
    extraAnnotations: {}
  serviceAccount:
    annotations: {}
    automountServiceAccountToken: true
    create: true
    name: null
  ssl:
    ca: null
    cert: null
    key: null
  sslmode: prefer
  tolerations: []
  topologySpreadConstraints: []
  uid: 65534
  verbose: 0
podTemplate: null
ports:
  airflowUI: 8080
  flowerUI: 5555
  pgbouncer: 6543
  pgbouncerScrape: 9127
  redisDB: 6379
  statsdIngest: 9125
  statsdScrape: 9102
  triggererLogs: 8794
  workerLogs: 8793
postgresql:
  architecture: standalone
  audit:
    clientMinMessages: error
    logConnections: false
    logDisconnections: false
    logHostname: false
    logLinePrefix: ""
    logTimezone: ""
    pgAuditLog: ""
    pgAuditLogCatalog: "off"
  auth:
    database: ""
    enablePostgresUser: true
    existingSecret: ""
    password: ""
    postgresPassword: postgres
    replicationPassword: ""
    replicationUsername: repl_user
    secretKeys:
      adminPasswordKey: postgres-password
      replicationPasswordKey: replication-password
      userPasswordKey: password
    usePasswordFiles: false
    username: ""
  backup:
    cronjob:
      annotations: {}
      command:
      - /bin/sh
      - -c
      - pg_dumpall --clean --if-exists --load-via-partition-root --quote-all-identifiers
        --no-password --file=${PGDUMP_DIR}/pg_dumpall-$(date '+%Y-%m-%d-%H-%M').pgdump
      concurrencyPolicy: Allow
      containerSecurityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsGroup: 0
        runAsNonRoot: true
        runAsUser: 1001
        seccompProfile:
          type: RuntimeDefault
      failedJobsHistoryLimit: 1
      labels: {}
      restartPolicy: OnFailure
      schedule: '@daily'
      startingDeadlineSeconds: ""
      storage:
        accessModes:
        - ReadWriteOnce
        annotations: {}
        existingClaim: ""
        mountPath: /backup/pgdump
        resourcePolicy: ""
        size: 8Gi
        storageClass: ""
        subPath: ""
        volumeClaimTemplates:
          selector: {}
      successfulJobsHistoryLimit: 3
      ttlSecondsAfterFinished: ""
    enabled: false
  clusterDomain: cluster.local
  common:
    exampleValue: common-chart
    global:
      imagePullSecrets: []
      imageRegistry: ""
      postgresql:
        auth:
          database: ""
          existingSecret: ""
          password: ""
          postgresPassword: ""
          secretKeys:
            adminPasswordKey: ""
            replicationPasswordKey: ""
            userPasswordKey: ""
          username: ""
        service:
          ports:
            postgresql: ""
      storageClass: ""
  commonAnnotations: {}
  commonLabels: {}
  containerPorts:
    postgresql: 5432
  diagnosticMode:
    args:
    - infinity
    command:
    - sleep
    enabled: false
  enabled: true
  extraDeploy: []
  fullnameOverride: ""
  global:
    imagePullSecrets: []
    imageRegistry: ""
    postgresql:
      auth:
        database: ""
        existingSecret: ""
        password: ""
        postgresPassword: ""
        secretKeys:
          adminPasswordKey: ""
          replicationPasswordKey: ""
          userPasswordKey: ""
        username: ""
      service:
        ports:
          postgresql: ""
    storageClass: ""
  image:
    debug: false
    digest: ""
    pullPolicy: IfNotPresent
    pullSecrets: []
    registry: docker.io
    repository: bitnami/postgresql
    tag: "11"
  kubeVersion: ""
  ldap:
    basedn: ""
    binddn: ""
    bindpw: ""
    enabled: false
    port: ""
    prefix: ""
    scheme: ""
    searchAttribute: ""
    searchFilter: ""
    server: ""
    suffix: ""
    tls:
      enabled: false
    uri: ""
  metrics:
    containerPorts:
      metrics: 9187
    containerSecurityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      enabled: true
      runAsGroup: 0
      runAsNonRoot: true
      runAsUser: 1001
      seccompProfile:
        type: RuntimeDefault
    customLivenessProbe: {}
    customMetrics: {}
    customReadinessProbe: {}
    customStartupProbe: {}
    enabled: false
    extraEnvVars: []
    image:
      digest: ""
      pullPolicy: IfNotPresent
      pullSecrets: []
      registry: docker.io
      repository: bitnami/postgres-exporter
      tag: 0.13.2-debian-11-r25
    livenessProbe:
      enabled: true
      failureThreshold: 6
      initialDelaySeconds: 5
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 5
    prometheusRule:
      enabled: false
      labels: {}
      namespace: ""
      rules: []
    readinessProbe:
      enabled: true
      failureThreshold: 6
      initialDelaySeconds: 5
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 5
    resources:
      limits: {}
      requests: {}
    service:
      annotations:
        prometheus.io/port: '{{ .Values.metrics.service.ports.metrics }}'
        prometheus.io/scrape: "true"
      clusterIP: ""
      ports:
        metrics: 9187
      sessionAffinity: None
    serviceMonitor:
      enabled: false
      honorLabels: false
      interval: ""
      jobLabel: ""
      labels: {}
      metricRelabelings: []
      namespace: ""
      relabelings: []
      scrapeTimeout: ""
      selector: {}
    startupProbe:
      enabled: false
      failureThreshold: 15
      initialDelaySeconds: 10
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 1
  nameOverride: ""
  networkPolicy:
    egressRules:
      customRules: []
      denyConnectionsToExternal: false
    enabled: false
    ingressRules:
      primaryAccessOnlyFrom:
        customRules: []
        enabled: false
        namespaceSelector: {}
        podSelector: {}
      readReplicasAccessOnlyFrom:
        customRules: []
        enabled: false
        namespaceSelector: {}
        podSelector: {}
    metrics:
      enabled: false
      namespaceSelector: {}
      podSelector: {}
  postgresqlDataDir: /bitnami/postgresql/data
  postgresqlSharedPreloadLibraries: pgaudit
  primary:
    affinity: {}
    annotations: {}
    args: []
    command: []
    configuration: ""
    containerSecurityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      enabled: true
      runAsGroup: 0
      runAsNonRoot: true
      runAsUser: 1001
      seccompProfile:
        type: RuntimeDefault
    customLivenessProbe: {}
    customReadinessProbe: {}
    customStartupProbe: {}
    existingConfigmap: ""
    existingExtendedConfigmap: ""
    extendedConfiguration: ""
    extraEnvVars: []
    extraEnvVarsCM: ""
    extraEnvVarsSecret: ""
    extraPodSpec: {}
    extraVolumeMounts: []
    extraVolumes: []
    hostAliases: []
    hostIPC: false
    hostNetwork: false
    initContainers: []
    initdb:
      args: ""
      password: ""
      postgresqlWalDir: ""
      scripts: {}
      scriptsConfigMap: ""
      scriptsSecret: ""
      user: ""
    labels: {}
    lifecycleHooks: {}
    livenessProbe:
      enabled: true
      failureThreshold: 6
      initialDelaySeconds: 30
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 5
    name: primary
    nodeAffinityPreset:
      key: ""
      type: ""
      values: []
    nodeSelector: {}
    persistence:
      accessModes:
      - ReadWriteOnce
      annotations: {}
      dataSource: {}
      enabled: true
      existingClaim: ""
      labels: {}
      mountPath: /bitnami/postgresql
      selector: {}
      size: 8Gi
      storageClass: ""
      subPath: ""
    persistentVolumeClaimRetentionPolicy:
      enabled: false
      whenDeleted: Retain
      whenScaled: Retain
    pgHbaConfiguration: ""
    podAffinityPreset: ""
    podAnnotations: {}
    podAntiAffinityPreset: soft
    podLabels: {}
    podSecurityContext:
      enabled: true
      fsGroup: 1001
    priorityClassName: ""
    readinessProbe:
      enabled: true
      failureThreshold: 6
      initialDelaySeconds: 5
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 5
    resources:
      limits: {}
      requests:
        cpu: 250m
        memory: 256Mi
    schedulerName: ""
    service:
      annotations: {}
      clusterIP: ""
      externalTrafficPolicy: Cluster
      extraPorts: []
      headless:
        annotations: {}
      loadBalancerIP: ""
      loadBalancerSourceRanges: []
      nodePorts:
        postgresql: ""
      ports:
        postgresql: 5432
      sessionAffinity: None
      sessionAffinityConfig: {}
      type: ClusterIP
    sidecars: []
    standby:
      enabled: false
      primaryHost: ""
      primaryPort: ""
    startupProbe:
      enabled: false
      failureThreshold: 15
      initialDelaySeconds: 30
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 1
    terminationGracePeriodSeconds: ""
    tolerations: []
    topologySpreadConstraints: []
    updateStrategy:
      rollingUpdate: {}
      type: RollingUpdate
  psp:
    create: false
  rbac:
    create: false
    rules: []
  readReplicas:
    affinity: {}
    annotations: {}
    args: []
    command: []
    containerSecurityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      enabled: true
      runAsGroup: 0
      runAsNonRoot: true
      runAsUser: 1001
      seccompProfile:
        type: RuntimeDefault
    customLivenessProbe: {}
    customReadinessProbe: {}
    customStartupProbe: {}
    extendedConfiguration: ""
    extraEnvVars: []
    extraEnvVarsCM: ""
    extraEnvVarsSecret: ""
    extraPodSpec: {}
    extraVolumeMounts: []
    extraVolumes: []
    hostAliases: []
    hostIPC: false
    hostNetwork: false
    initContainers: []
    labels: {}
    lifecycleHooks: {}
    livenessProbe:
      enabled: true
      failureThreshold: 6
      initialDelaySeconds: 30
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 5
    name: read
    nodeAffinityPreset:
      key: ""
      type: ""
      values: []
    nodeSelector: {}
    persistence:
      accessModes:
      - ReadWriteOnce
      annotations: {}
      dataSource: {}
      enabled: true
      existingClaim: ""
      labels: {}
      mountPath: /bitnami/postgresql
      selector: {}
      size: 8Gi
      storageClass: ""
      subPath: ""
    persistentVolumeClaimRetentionPolicy:
      enabled: false
      whenDeleted: Retain
      whenScaled: Retain
    podAffinityPreset: ""
    podAnnotations: {}
    podAntiAffinityPreset: soft
    podLabels: {}
    podSecurityContext:
      enabled: true
      fsGroup: 1001
    priorityClassName: ""
    readinessProbe:
      enabled: true
      failureThreshold: 6
      initialDelaySeconds: 5
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 5
    replicaCount: 1
    resources:
      limits: {}
      requests:
        cpu: 250m
        memory: 256Mi
    schedulerName: ""
    service:
      annotations: {}
      clusterIP: ""
      externalTrafficPolicy: Cluster
      extraPorts: []
      headless:
        annotations: {}
      loadBalancerIP: ""
      loadBalancerSourceRanges: []
      nodePorts:
        postgresql: ""
      ports:
        postgresql: 5432
      sessionAffinity: None
      sessionAffinityConfig: {}
      type: ClusterIP
    sidecars: []
    startupProbe:
      enabled: false
      failureThreshold: 15
      initialDelaySeconds: 30
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 1
    terminationGracePeriodSeconds: ""
    tolerations: []
    topologySpreadConstraints: []
    updateStrategy:
      rollingUpdate: {}
      type: RollingUpdate
  replication:
    applicationName: my_application
    numSynchronousReplicas: 0
    synchronousCommit: "off"
  serviceAccount:
    annotations: {}
    automountServiceAccountToken: true
    create: false
    name: ""
  serviceBindings:
    enabled: false
  shmVolume:
    enabled: true
    sizeLimit: ""
  tls:
    autoGenerated: false
    certCAFilename: ""
    certFilename: ""
    certKeyFilename: ""
    certificatesSecret: ""
    crlFilename: ""
    enabled: false
    preferServerCiphers: true
  volumePermissions:
    containerSecurityContext:
      runAsGroup: 0
      runAsNonRoot: false
      runAsUser: 0
      seccompProfile:
        type: RuntimeDefault
    enabled: false
    image:
      digest: ""
      pullPolicy: IfNotPresent
      pullSecrets: []
      registry: docker.io
      repository: bitnami/os-shell
      tag: 11-debian-11-r43
    resources:
      limits: {}
      requests: {}
priorityClasses: []
quotas: {}
rbac:
  create: true
  createSCCRoleBinding: false
redis:
  affinity: {}
  containerLifecycleHooks: {}
  enabled: true
  nodeSelector: {}
  password: null
  passwordSecretName: null
  persistence:
    annotations: {}
    enabled: true
    size: 1Gi
    storageClassName: null
  podAnnotations: {}
  resources: {}
  safeToEvict: true
  securityContext: {}
  securityContexts:
    container: {}
    pod: {}
  serviceAccount:
    annotations: {}
    automountServiceAccountToken: true
    create: true
    name: null
  terminationGracePeriodSeconds: 600
  tolerations: []
  topologySpreadConstraints: []
  uid: 0
registry:
  connection: {}
  secretName: null
revisionHistoryLimit: null
scheduler:
  affinity: {}
  annotations: {}
  args:
  - bash
  - -c
  - exec airflow scheduler
  command: null
  containerLifecycleHooks: {}
  env: []
  extraContainers: []
  extraInitContainers: []
  extraVolumeMounts: []
  extraVolumes: []
  hostAliases: []
  labels: {}
  livenessProbe:
    command: null
    failureThreshold: 5
    initialDelaySeconds: 10
    periodSeconds: 60
    timeoutSeconds: 20
  logGroomerSidecar:
    args:
    - bash
    - /clean-logs
    command: null
    containerLifecycleHooks: {}
    enabled: true
    resources: {}
    retentionDays: 15
    securityContexts:
      container: {}
  nodeSelector: {}
  podAnnotations: {}
  podDisruptionBudget:
    config:
      maxUnavailable: 1
    enabled: false
  priorityClassName: null
  replicas: 1
  resources: {}
  revisionHistoryLimit: null
  safeToEvict: true
  securityContext: {}
  securityContexts:
    container: {}
    pod: {}
  serviceAccount:
    annotations: {}
    automountServiceAccountToken: true
    create: true
    name: null
  startupProbe:
    command: null
    failureThreshold: 6
    periodSeconds: 10
    timeoutSeconds: 20
  strategy: null
  tolerations: []
  topologySpreadConstraints: []
  updateStrategy: null
  waitForMigrations:
    enabled: true
    env: []
    securityContexts:
      container: {}
schedulerName: null
secret: []
securityContext: {}
securityContexts:
  containers: {}
  pod: {}
statsd:
  affinity: {}
  annotations: {}
  args:
  - --statsd.mapping-config=/etc/statsd-exporter/mappings.yml
  configMapAnnotations: {}
  containerLifecycleHooks: {}
  enabled: true
  env: []
  extraMappings: []
  extraNetworkPolicies: []
  nodeSelector: {}
  overrideMappings: []
  podAnnotations: {}
  priorityClassName: null
  resources: {}
  revisionHistoryLimit: null
  securityContext: {}
  securityContexts:
    container: {}
    pod: {}
  service:
    extraAnnotations: {}
  serviceAccount:
    annotations: {}
    automountServiceAccountToken: true
    create: true
    name: null
  tolerations: []
  topologySpreadConstraints: []
  uid: 65534
tolerations: []
topologySpreadConstraints: []
triggerer:
  affinity: {}
  annotations: {}
  args:
  - bash
  - -c
  - exec airflow triggerer
  command: null
  containerLifecycleHooks: {}
  enabled: true
  env: []
  extraContainers: []
  extraInitContainers: []
  extraVolumeMounts: []
  extraVolumes: []
  keda:
    advanced: {}
    cooldownPeriod: 30
    enabled: false
    maxReplicaCount: 10
    minReplicaCount: 0
    namespaceLabels: {}
    pollingInterval: 5
    query: SELECT ceil(COUNT(*)::decimal / {{ .Values.config.triggerer.default_capacity
      }}) FROM trigger
  labels: {}
  livenessProbe:
    command: null
    failureThreshold: 5
    initialDelaySeconds: 10
    periodSeconds: 60
    timeoutSeconds: 20
  logGroomerSidecar:
    args:
    - bash
    - /clean-logs
    command: null
    containerLifecycleHooks: {}
    enabled: true
    resources: {}
    retentionDays: 15
    securityContexts:
      container: {}
  nodeSelector: {}
  persistence:
    annotations: {}
    enabled: true
    fixPermissions: false
    size: 100Gi
    storageClassName: null
  podAnnotations: {}
  priorityClassName: null
  replicas: 1
  resources: {}
  revisionHistoryLimit: null
  safeToEvict: true
  securityContext: {}
  securityContexts:
    container: {}
    pod: {}
  serviceAccount:
    annotations: {}
    automountServiceAccountToken: true
    create: true
    name: null
  strategy:
    rollingUpdate:
      maxSurge: 100%
      maxUnavailable: 50%
  terminationGracePeriodSeconds: 60
  tolerations: []
  topologySpreadConstraints: []
  updateStrategy: null
  waitForMigrations:
    enabled: true
    env: []
    securityContexts:
      container: {}
uid: 50000
useStandardNaming: false
volumeMounts: []
volumes: []
webserver:
  affinity: {}
  allowPodLogReading: true
  annotations: {}
  args:
  - bash
  - -c
  - exec airflow webserver
  command: null
  configMapAnnotations: {}
  containerLifecycleHooks: {}
  defaultUser:
    email: admin@example.com
    enabled: true
    firstName: admin
    lastName: user
    password: admin
    role: Admin
    username: admin
  env: []
  extraContainers: []
  extraInitContainers: []
  extraNetworkPolicies: []
  extraVolumeMounts: []
  extraVolumes: []
  hostAliases: []
  labels: {}
  livenessProbe:
    failureThreshold: 5
    initialDelaySeconds: 15
    periodSeconds: 10
    scheme: HTTP
    timeoutSeconds: 5
  networkPolicy:
    ingress:
      from: []
      ports:
      - port: '{{ .Values.ports.airflowUI }}'
  nodeSelector: {}
  podAnnotations: {}
  podDisruptionBudget:
    config:
      maxUnavailable: 1
    enabled: false
  priorityClassName: null
  readinessProbe:
    failureThreshold: 5
    initialDelaySeconds: 15
    periodSeconds: 10
    scheme: HTTP
    timeoutSeconds: 5
  replicas: 1
  resources: {}
  revisionHistoryLimit: null
  securityContext: {}
  securityContexts:
    container: {}
    pod: {}
  service:
    annotations: {}
    loadBalancerIP: null
    loadBalancerSourceRanges: []
    ports:
    - name: airflow-ui
      port: '{{ .Values.ports.airflowUI }}'
    type: ClusterIP
  serviceAccount:
    annotations: {}
    automountServiceAccountToken: true
    create: true
    name: null
  startupProbe:
    failureThreshold: 6
    periodSeconds: 10
    scheme: HTTP
    timeoutSeconds: 20
  strategy: null
  tolerations: []
  topologySpreadConstraints: []
  waitForMigrations:
    enabled: true
    env: []
    securityContexts:
      container: {}
  webserverConfig: null
  webserverConfigConfigMapName: null
webserverSecretKey: null
webserverSecretKeySecretName: null
workers:
  affinity: {}
  annotations: {}
  args:
  - bash
  - -c
  - |-
    exec \
    airflow {{ semverCompare ">=2.0.0" .Values.airflowVersion | ternary "celery worker" "worker" }}
  command: null
  containerLifecycleHooks: {}
  env: []
  extraContainers: []
  extraInitContainers: []
  extraVolumeMounts: []
  extraVolumes: []
  hostAliases: []
  keda:
    advanced: {}
    cooldownPeriod: 30
    enabled: false
    maxReplicaCount: 10
    minReplicaCount: 0
    namespaceLabels: {}
    pollingInterval: 5
    query: SELECT ceil(COUNT(*)::decimal / {{ .Values.config.celery.worker_concurrency
      }}) FROM task_instance WHERE (state='running' OR state='queued') {{- if eq .Values.executor
      "CeleryKubernetesExecutor" }} AND queue != '{{ .Values.config.celery_kubernetes_executor.kubernetes_queue
      }}' {{- end }}
    usePgbouncer: true
  kerberosSidecar:
    containerLifecycleHooks: {}
    enabled: false
    resources: {}
    securityContexts:
      container: {}
  labels: {}
  livenessProbe:
    command: null
    enabled: true
    failureThreshold: 5
    initialDelaySeconds: 10
    periodSeconds: 60
    timeoutSeconds: 20
  logGroomerSidecar:
    args:
    - bash
    - /clean-logs
    command: null
    enabled: true
    resources: {}
    retentionDays: 15
    securityContexts:
      container: {}
  nodeSelector: {}
  persistence:
    annotations: {}
    containerLifecycleHooks: {}
    enabled: true
    fixPermissions: false
    securityContexts:
      container: {}
    size: 100Gi
    storageClassName: null
  podAnnotations: {}
  priorityClassName: null
  replicas: 1
  resources: {}
  revisionHistoryLimit: null
  runtimeClassName: null
  safeToEvict: true
  securityContext: {}
  securityContexts:
    container: {}
    pod: {}
  serviceAccount:
    annotations: {}
    automountServiceAccountToken: true
    create: true
    name: null
  strategy:
    rollingUpdate:
      maxSurge: 100%
      maxUnavailable: 50%
  terminationGracePeriodSeconds: 600
  tolerations: []
  topologySpreadConstraints: []
  updateStrategy: null
  waitForMigrations:
    enabled: true
    env: []
    securityContexts:
      container: {}

HOOKS:
---
# Source: airflow/templates/secrets/fernetkey-secret.yaml
################################
## Airflow Fernet Key Secret
#################################
apiVersion: v1
kind: Secret
metadata:
  name: airflow-fernet-key
  labels:
    tier: airflow
    release: airflow
    chart: airflow
    heritage: Helm
  annotations:
    "helm.sh/hook": "pre-install"
    "helm.sh/hook-delete-policy": "before-hook-creation"
    "helm.sh/hook-weight": "0"
type: Opaque
data:
  fernet-key: "T0dwR2FXRlNWSEpOYjNKSmQyRlVNV05WYVZZNVQwdGlWMnBPUWpSVVMyMD0="
---
# Source: airflow/templates/secrets/redis-secrets.yaml
# We will create these secrets (if necessary) _even if_ we aren't
# currently using CeleryExecutor or CeleryKubernetesExecutor. As we are
# relying on the "pre-install" hack to prevent changing randomly generated passwords,
# updating the executor later doesn't give us the opportunity to deploy them
# when we need them. We will always deploy them defensively to make the executor
# update path actually work.

################################
## Airflow Redis Password Secret
#################################
# If passwordSecretName is not set, we will either use the set password, or use the generated one
apiVersion: v1
kind: Secret
metadata:
  name: airflow-redis-password
  labels:
    tier: airflow
    component: redis
    release: airflow
    chart: airflow
    heritage: Helm
  annotations:
    "helm.sh/hook": "pre-install"
    "helm.sh/hook-delete-policy": "before-hook-creation"
    "helm.sh/hook-weight": "0"
type: Opaque
data:
  password: "cEdsQ1RTZ2tUeg=="
---
# Source: airflow/templates/secrets/redis-secrets.yaml
##################################
## Airflow Redis Connection Secret
##################################
apiVersion: v1
kind: Secret
metadata:
  name: airflow-broker-url
  labels:
    tier: airflow
    component: redis
    release: airflow
    chart: airflow
    heritage: Helm
  annotations:
    "helm.sh/hook": "pre-install"
    "helm.sh/hook-delete-policy": "before-hook-creation"
    "helm.sh/hook-weight": "0"
type: Opaque
data:
  connection: "cmVkaXM6Ly86cEdsQ1RTZ2tUekBhaXJmbG93LXJlZGlzOjYzNzkvMA=="
---
# Source: airflow/templates/jobs/create-user-job.yaml
################################
## Airflow Create User Job
#################################
apiVersion: batch/v1
kind: Job
metadata:
  name: airflow-create-user
  labels:
    tier: airflow
    component: create-user-job
    release: airflow
    chart: "airflow-1.11.0"
    heritage: Helm
  annotations:
    helm.sh/hook: post-install,post-upgrade
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
    helm.sh/hook-weight: "2"
spec:
  ttlSecondsAfterFinished: 300
  template:
    metadata:
      labels:
        tier: airflow
        component: create-user-job
        release: airflow
    spec:
      securityContext: 
        runAsUser: 50000
        fsGroup: 0
      restartPolicy: OnFailure
      nodeSelector:
        {}
      affinity:
        {}
      tolerations:
        []
      topologySpreadConstraints:
        []
      serviceAccountName: airflow-create-user-job
      containers:
        - name: create-user
          image: apache/airflow:2.7.1
          imagePullPolicy: IfNotPresent
          securityContext: 
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
          args: 
            - bash
            - -c
            - |-
              exec \
              airflow users create "$@"
            - --
            - -r
            - 'Admin'
            - -u
            - 'admin'
            - -e
            - 'admin@example.com'
            - -f
            - 'admin'
            - -l
            - 'user'
            - -p
            - 'admin'
          envFrom:          
            []
          env:          
            # Dynamically created environment variables
            - name: OPENLINEAGE_NAMESPACE
              value: "airflow"
            # Dynamically created secret envs
            # Extra env          
            # Hard Coded Airflow Envs
            - name: AIRFLOW__CORE__FERNET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-fernet-key
                  key: fernet-key
            # For Airflow <2.3, backward compatibility; moved to [database] in 2.3
            - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW_CONN_AIRFLOW_DB
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW__WEBSERVER__SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-webserver-secret-key
                  key: webserver-secret-key
            - name: AIRFLOW__CELERY__BROKER_URL
              valueFrom:
                secretKeyRef:
                  name: airflow-broker-url
                  key: connection          
          resources:
            {}
          volumeMounts:
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
            - name: config
              mountPath: "/opt/airflow/config/airflow_local_settings.py"
              subPath: airflow_local_settings.py
              readOnly: true
      volumes:
        - name: config
          configMap:
            name: airflow-config
---
# Source: airflow/templates/jobs/migrate-database-job.yaml
################################
## Airflow Run Migrations
#################################
apiVersion: batch/v1
kind: Job
metadata:
  name: airflow-run-airflow-migrations
  labels:
    tier: airflow
    component: run-airflow-migrations
    release: airflow
    chart: "airflow-1.11.0"
    heritage: Helm
  annotations:
    helm.sh/hook: post-install,post-upgrade
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
    helm.sh/hook-weight: "1"
spec:
  ttlSecondsAfterFinished: 300
  template:
    metadata:
      labels:
        tier: airflow
        component: run-airflow-migrations
        release: airflow
    spec:
      securityContext: 
        runAsUser: 50000
        fsGroup: 0
      restartPolicy: OnFailure
      nodeSelector:
        {}
      affinity:
        {}
      tolerations:
        []
      topologySpreadConstraints:
        []
      serviceAccountName: airflow-migrate-database-job
      containers:
        - name: run-airflow-migrations
          image: apache/airflow:2.7.1
          imagePullPolicy: IfNotPresent
          securityContext: 
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
          args:
            - bash
            - -c
            - |-
              exec \
              airflow db migrate
          envFrom:          
            []
          env:          
            # Dynamically created environment variables
            - name: OPENLINEAGE_NAMESPACE
              value: "airflow"
            # Dynamically created secret envs
            # Extra env
            - name: PYTHONUNBUFFERED
              value: "1"          
            # Hard Coded Airflow Envs
            - name: AIRFLOW__CORE__FERNET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-fernet-key
                  key: fernet-key
            # For Airflow <2.3, backward compatibility; moved to [database] in 2.3
            - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW_CONN_AIRFLOW_DB
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW__WEBSERVER__SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-webserver-secret-key
                  key: webserver-secret-key
            - name: AIRFLOW__CELERY__BROKER_URL
              valueFrom:
                secretKeyRef:
                  name: airflow-broker-url
                  key: connection
          resources:
            {}
          volumeMounts:
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
            - name: config
              mountPath: "/opt/airflow/config/airflow_local_settings.py"
              subPath: airflow_local_settings.py
              readOnly: true
      volumes:
        - name: config
          configMap:
            name: airflow-config
MANIFEST:
---
# Source: airflow/templates/jobs/create-user-job-serviceaccount.yaml
###########################################
## Airflow Create User Job ServiceAccount
###########################################
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  name: airflow-create-user-job
  labels:
    tier: airflow
    component: create-user-job
    release: airflow
    chart: "airflow-1.11.0"
    heritage: Helm
---
# Source: airflow/templates/jobs/migrate-database-job-serviceaccount.yaml
#############################################
## Airflow Migrate Database Job ServiceAccount
##############################################
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  name: airflow-migrate-database-job
  labels:
    tier: airflow
    component: run-airflow-migrations
    release: airflow
    chart: "airflow-1.11.0"
    heritage: Helm
---
# Source: airflow/templates/redis/redis-serviceaccount.yaml
######################################
## Airflow Redis ServiceAccount
######################################
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  name: airflow-redis
  labels:
    tier: airflow
    component: redis
    release: airflow
    chart: "airflow-1.11.0"
    heritage: Helm
---
# Source: airflow/templates/scheduler/scheduler-serviceaccount.yaml
################################
## Airflow Scheduler ServiceAccount
#################################
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  name: airflow-scheduler
  labels:
    tier: airflow
    component: scheduler
    release: airflow
    chart: "airflow-1.11.0"
    heritage: Helm
---
# Source: airflow/templates/statsd/statsd-serviceaccount.yaml
######################################
## Airflow StatsD ServiceAccount
######################################
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  name: airflow-statsd
  labels:
    tier: airflow
    component: statsd
    release: airflow
    chart: "airflow-1.11.0"
    heritage: Helm
---
# Source: airflow/templates/triggerer/triggerer-serviceaccount.yaml
################################
## Airflow Triggerer ServiceAccount
#################################
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  name: airflow-triggerer
  labels:
    tier: airflow
    component: triggerer
    release: airflow
    chart: "airflow-1.11.0"
    heritage: Helm
---
# Source: airflow/templates/webserver/webserver-serviceaccount.yaml
######################################
## Airflow Webserver ServiceAccount
######################################
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  name: airflow-webserver
  labels:
    tier: airflow
    component: webserver
    release: airflow
    chart: "airflow-1.11.0"
    heritage: Helm
---
# Source: airflow/templates/workers/worker-serviceaccount.yaml
################################
## Airflow Worker ServiceAccount
#################################
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  name: airflow-worker
  labels:
    tier: airflow
    component: worker
    release: airflow
    chart: "airflow-1.11.0"
    heritage: Helm
---
# Source: airflow/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: airflow-postgresql
  namespace: "airflow"
  labels:
    app.kubernetes.io/instance: airflow
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.10.0
type: Opaque
data:
  postgres-password: "cG9zdGdyZXM="
  # We don't auto-generate LDAP password when it's not provided as we do for other passwords
---
# Source: airflow/templates/secrets/metadata-connection-secret.yaml
################################
## Airflow Metadata Secret
#################################
apiVersion: v1
kind: Secret
metadata:
  name: airflow-metadata
  labels:
    tier: airflow
    release: airflow
    chart: airflow
    heritage: Helm
type: Opaque
data:
  connection: "cG9zdGdyZXNxbDovL3Bvc3RncmVzOnBvc3RncmVzQGFpcmZsb3ctcG9zdGdyZXNxbC5haXJmbG93OjU0MzIvcG9zdGdyZXM/c3NsbW9kZT1kaXNhYmxl"
---
# Source: airflow/templates/secrets/webserver-secret-key-secret.yaml
############################################
## Airflow Webserver Flask Secret Key Secret
############################################

apiVersion: v1
kind: Secret
metadata:
  name: airflow-webserver-secret-key
  labels:
    tier: airflow
    component: webserver
    release: airflow
    chart: airflow
    heritage: Helm
type: Opaque
data:
  webserver-secret-key: "U0U1NmJqQkNUV0pwTUVGRU5ucEVhSFl4WVV4aGQyeExUVmhIVkhoc05tRT0="
---
# Source: airflow/templates/configmaps/configmap.yaml
################################
## Airflow ConfigMap
#################################
apiVersion: v1
kind: ConfigMap
metadata:
  name: airflow-config
  labels:
    tier: airflow
    component: config
    release: airflow
    chart: "airflow-1.11.0"
    heritage: Helm
data:
  # These are system-specified config overrides.
  airflow.cfg: |-
    [celery]
    flower_url_prefix = 
    worker_concurrency = 16
    
    [celery_kubernetes_executor]
    kubernetes_queue = kubernetes
    
    [core]
    colored_console_log = False
    dags_folder = /opt/airflow/dags
    executor = CeleryExecutor
    load_examples = False
    remote_logging = False
    
    [elasticsearch]
    json_format = True
    log_id_template = {dag_id}_{task_id}_{execution_date}_{try_number}
    
    [elasticsearch_configs]
    max_retries = 3
    retry_timeout = True
    timeout = 30
    
    [kerberos]
    ccache = /var/kerberos-ccache/cache
    keytab = /etc/airflow.keytab
    principal = airflow@FOO.COM
    reinit_frequency = 3600
    
    [kubernetes]
    airflow_configmap = airflow-config
    airflow_local_settings_configmap = airflow-config
    multi_namespace_mode = False
    namespace = airflow
    pod_template_file = /opt/airflow/pod_templates/pod_template_file.yaml
    worker_container_repository = apache/airflow
    worker_container_tag = 2.7.1
    
    [kubernetes_executor]
    multi_namespace_mode = False
    namespace = airflow
    pod_template_file = /opt/airflow/pod_templates/pod_template_file.yaml
    worker_container_repository = apache/airflow
    worker_container_tag = 2.7.1
    
    [logging]
    colored_console_log = False
    remote_logging = False
    
    [metrics]
    statsd_host = airflow-statsd
    statsd_on = True
    statsd_port = 9125
    statsd_prefix = airflow
    
    [scheduler]
    run_duration = 41460
    standalone_dag_processor = False
    statsd_host = airflow-statsd
    statsd_on = True
    statsd_port = 9125
    statsd_prefix = airflow
    
    [triggerer]
    default_capacity = 1000
    
    [webserver]
    enable_proxy_fix = True
    rbac = True
    
  airflow_local_settings.py: |-
    
    from airflow.www.utils import UIAlert
    
    DASHBOARD_UIALERTS = [
      UIAlert(
        'Usage of a dynamic webserver secret key detected. We recommend a static webserver secret key instead.'
        ' See the <a href='
        '"https://airflow.apache.org/docs/helm-chart/stable/production-guide.html#webserver-secret-key">'
        'Helm Chart Production Guide</a> for more details.',
        category="warning",
        roles=["Admin"],
        html=True,
      )
    ]
---
# Source: airflow/templates/configmaps/statsd-configmap.yaml
################################
## Airflow StatsD ConfigMap
#################################
apiVersion: v1
kind: ConfigMap
metadata:
  name: airflow-statsd
  labels:
    tier: airflow
    component: config
    release: airflow
    chart: "airflow-1.11.0"
    heritage: Helm
data:
  mappings.yml: |-
    # Licensed to the Apache Software Foundation (ASF) under one
    # or more contributor license agreements.  See the NOTICE file
    # distributed with this work for additional information
    # regarding copyright ownership.  The ASF licenses this file
    # to you under the Apache License, Version 2.0 (the
    # "License"); you may not use this file except in compliance
    # with the License.  You may obtain a copy of the License at
    #
    #   http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing,
    # software distributed under the License is distributed on an
    # "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
    # KIND, either express or implied.  See the License for the
    # specific language governing permissions and limitations
    # under the License.
    ---
    mappings:
      # Map dot separated stats to labels
      - match: airflow.dagrun.dependency-check.*.*
        name: "airflow_dagrun_dependency_check"
        labels:
          dag_id: "$1"
    
      - match: airflow.operator_successes_(.*)
        match_type: regex
        name: "airflow_operator_successes"
        labels:
          operator: "$1"
    
      - match: airflow.operator_failures_(.*)
        match_type: regex
        name: "airflow_operator_failures"
        labels:
          operator: "$1"
    
      - match: airflow.scheduler_heartbeat
        match_type: regex
        name: "airflow_scheduler_heartbeat"
        labels:
          type: counter
    
      - match: airflow.dag.*.*.duration
        name: "airflow_task_duration"
        labels:
          dag_id: "$1"
          task_id: "$2"
    
      - match: airflow.dagrun.duration.success.*
        name: "airflow_dagrun_duration"
        labels:
          dag_id: "$1"
    
      - match: airflow.dagrun.duration.failed.*
        name: "airflow_dagrun_failed"
        labels:
          dag_id: "$1"
    
      - match: airflow.dagrun.schedule_delay.*
        name: "airflow_dagrun_schedule_delay"
        labels:
          dag_id: "$1"
    
      - match: airflow.dag_processing.last_runtime.*
        name: "airflow_dag_processing_last_runtime"
        labels:
          dag_file: "$1"
    
      - match: airflow.dag_processing.last_run.seconds_ago.*
        name: "airflow_dag_processing_last_run_seconds_ago"
        labels:
          dag_file: "$1"
    
      - match: airflow.pool.open_slots.*
        name: "airflow_pool_open_slots"
        labels:
          pool: "$1"
    
      - match: airflow.pool.used_slots.*
        name: "airflow_pool_used_slots"
        labels:
          pool: "$1"
    
      - match: airflow.pool.starving_tasks.*
        name: "airflow_pool_starving_tasks"
        labels:
          pool: "$1"
---
# Source: airflow/templates/rbac/pod-launcher-role.yaml
################################
## Airflow Pod Launcher Role
#################################
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: airflow-pod-launcher-role
  namespace: "airflow"
  labels:
    tier: airflow
    release: airflow
    chart: "airflow-1.11.0"
    heritage: Helm
rules:
  - apiGroups:
      - ""
    resources:
      - "pods"
    verbs:
      - "create"
      - "list"
      - "get"
      - "patch"
      - "watch"
      - "delete"
  - apiGroups:
      - ""
    resources:
      - "pods/log"
    verbs:
      - "get"
  - apiGroups:
      - ""
    resources:
      - "pods/exec"
    verbs:
      - "create"
      - "get"
  - apiGroups:
      - ""
    resources:
      - "events"
    verbs:
      - "list"
---
# Source: airflow/templates/rbac/pod-log-reader-role.yaml
################################
## Airflow Pod Reader Role
#################################
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: airflow-pod-log-reader-role
  namespace: "airflow"
  labels:
    tier: airflow
    release: airflow
    chart: "airflow-1.11.0"
    heritage: Helm
rules:
  - apiGroups:
      - ""
    resources:
      - "pods"
    verbs:
      - "list"
      - "get"
      - "watch"
  - apiGroups:
      - ""
    resources:
      - "pods/log"
    verbs:
      - "get"
      - "list"
---
# Source: airflow/templates/rbac/pod-launcher-rolebinding.yaml
################################
## Airflow Pod Launcher Role Binding
#################################
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  namespace: "airflow"
  name: airflow-pod-launcher-rolebinding
  labels:
    tier: airflow
    release: airflow
    chart: "airflow-1.11.0"
    heritage: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: airflow-pod-launcher-role
subjects:
  - kind: ServiceAccount
    name: airflow-worker
    namespace: "airflow"
---
# Source: airflow/templates/rbac/pod-log-reader-rolebinding.yaml
################################
## Airflow Pod Reader Role Binding
#################################
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  namespace: "airflow"
  name: airflow-pod-log-reader-rolebinding
  labels:
    tier: airflow
    release: airflow
    chart: "airflow-1.11.0"
    heritage: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: airflow-pod-log-reader-role
subjects:
  - kind: ServiceAccount
    name: airflow-webserver
    namespace: "airflow"
  - kind: ServiceAccount
    name: airflow-triggerer
    namespace: "airflow"
---
# Source: airflow/charts/postgresql/templates/primary/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: airflow-postgresql-hl
  namespace: "airflow"
  labels:
    app.kubernetes.io/instance: airflow
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.10.0
    app.kubernetes.io/component: primary
  annotations:
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/instance: airflow
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: airflow/charts/postgresql/templates/primary/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: airflow-postgresql
  namespace: "airflow"
  labels:
    app.kubernetes.io/instance: airflow
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.10.0
    app.kubernetes.io/component: primary
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
      nodePort: null
  selector:
    app.kubernetes.io/instance: airflow
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: airflow/templates/redis/redis-service.yaml
################################
## Airflow Redis Service
#################################
apiVersion: v1
kind: Service
metadata:
  name: airflow-redis
  labels:
    tier: airflow
    component: redis
    release: airflow
    chart: "airflow-1.11.0"
    heritage: Helm
spec:
  type: ClusterIP
  selector:
    tier: airflow
    component: redis
    release: airflow
  ports:
    - name: redis-db
      protocol: TCP
      port: 6379
      targetPort: 6379
---
# Source: airflow/templates/statsd/statsd-service.yaml
################################
## Airflow StatsD Service
#################################
apiVersion: v1
kind: Service
metadata:
  name: airflow-statsd
  labels:
    tier: airflow
    component: statsd
    release: airflow
    chart: "airflow-1.11.0"
    heritage: Helm
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9102"
spec:
  type: ClusterIP
  selector:
    tier: airflow
    component: statsd
    release: airflow
  ports:
    - name: statsd-ingest
      protocol: UDP
      port: 9125
      targetPort: 9125
    - name: statsd-scrape
      protocol: TCP
      port: 9102
      targetPort: 9102
---
# Source: airflow/templates/triggerer/triggerer-service.yaml
################################
## Airflow triggerer Service
#################################
apiVersion: v1
kind: Service
metadata:
  name: airflow-triggerer
  labels:
    tier: airflow
    component: triggerer
    release: airflow
    chart: "airflow-1.11.0"
    heritage: Helm
spec:
  clusterIP: None
  selector:
    tier: airflow
    component: triggerer
    release: airflow
  ports:
    - name: triggerer-logs
      protocol: TCP
      port: 8794
      targetPort: 8794
---
# Source: airflow/templates/webserver/webserver-service.yaml
################################
## Airflow Webserver Service
#################################
apiVersion: v1
kind: Service
metadata:
  name: airflow-webserver
  labels:
    tier: airflow
    component: webserver
    release: airflow
    chart: "airflow-1.11.0"
    heritage: Helm
spec:
  type: ClusterIP
  selector:
    tier: airflow
    component: webserver
    release: airflow
  ports:
    - name: airflow-ui
      port: 8080
---
# Source: airflow/templates/workers/worker-service.yaml
################################
## Airflow Worker Service
#################################
apiVersion: v1
kind: Service
metadata:
  name: airflow-worker
  labels:
    tier: airflow
    component: worker
    release: airflow
    chart: "airflow-1.11.0"
    heritage: Helm
spec:
  clusterIP: None
  selector:
    tier: airflow
    component: worker
    release: airflow
  ports:
    - name: worker-logs
      protocol: TCP
      port: 8793
      targetPort: 8793
---
# Source: airflow/templates/scheduler/scheduler-deployment.yaml
################################
## Airflow Scheduler Deployment/StatefulSet
#################################

# Are we using a local executor?
# Is persistence enabled on the _workers_?
# This is important because in $local mode, the scheduler assumes the role of the worker
# If we're using a StatefulSet
# We can skip DAGs mounts on scheduler if dagProcessor is enabled, except with $local mode
# If we're using elasticsearch logging
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-scheduler
  labels:
    tier: airflow
    component: scheduler
    release: airflow
    chart: "airflow-1.11.0"
    heritage: Helm
    executor: CeleryExecutor
spec:
  replicas: 1
  selector:
    matchLabels:
      tier: airflow
      component: scheduler
      release: airflow
  template:
    metadata:
      labels:
        tier: airflow
        component: scheduler
        release: airflow
      annotations:
        checksum/metadata-secret: 1527346545415bf13f4c9ad69470086eb90d854f2b83594d78ec1badb5e13eb0
        checksum/result-backend-secret: 98a68f230007cfa8f5d3792e1aff843a76b0686409e4a46ab2f092f6865a1b71
        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688
        checksum/airflow-config: 2bb0efc29b918ce453fdfc4eaa785e4c824f3f3b8284164228bbe9f76812a650
        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8
        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827
        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
    spec:
      nodeSelector:
        {}
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  component: scheduler
              topologyKey: kubernetes.io/hostname
            weight: 100
      tolerations:
        []
      topologySpreadConstraints:
        []
      restartPolicy: Always
      terminationGracePeriodSeconds: 10
      serviceAccountName: airflow-scheduler
      securityContext: 
        runAsUser: 50000
        fsGroup: 0
      initContainers:
        - name: wait-for-airflow-migrations
          resources:
            {}
          image: apache/airflow:2.7.1
          imagePullPolicy: IfNotPresent
          securityContext: 
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
          volumeMounts:
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
            - name: config
              mountPath: "/opt/airflow/config/airflow_local_settings.py"
              subPath: airflow_local_settings.py
              readOnly: true
          args:          
            - airflow
            - db
            - check-migrations
            - --migration-wait-timeout=60
          envFrom:          
            []
          env:          
            # Dynamically created environment variables
            - name: OPENLINEAGE_NAMESPACE
              value: "airflow"
            # Dynamically created secret envs
            # Extra env          
            # Hard Coded Airflow Envs
            - name: AIRFLOW__CORE__FERNET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-fernet-key
                  key: fernet-key
            # For Airflow <2.3, backward compatibility; moved to [database] in 2.3
            - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW_CONN_AIRFLOW_DB
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW__WEBSERVER__SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-webserver-secret-key
                  key: webserver-secret-key
            - name: AIRFLOW__CELERY__BROKER_URL
              valueFrom:
                secretKeyRef:
                  name: airflow-broker-url
                  key: connection
      containers:
        # Always run the main scheduler container.
        - name: scheduler
          image: apache/airflow:2.7.1
          imagePullPolicy: IfNotPresent
          securityContext: 
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
          args: 
            - bash
            - -c
            - exec airflow scheduler
          envFrom:          
            []
          env:          
            # Dynamically created environment variables
            - name: OPENLINEAGE_NAMESPACE
              value: "airflow"
            # Dynamically created secret envs
            # Extra env          
            # Hard Coded Airflow Envs
            - name: AIRFLOW__CORE__FERNET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-fernet-key
                  key: fernet-key
            # For Airflow <2.3, backward compatibility; moved to [database] in 2.3
            - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW_CONN_AIRFLOW_DB
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW__WEBSERVER__SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-webserver-secret-key
                  key: webserver-secret-key
            - name: AIRFLOW__CELERY__BROKER_URL
              valueFrom:
                secretKeyRef:
                  name: airflow-broker-url
                  key: connection          
          livenessProbe:
            initialDelaySeconds: 10
            timeoutSeconds: 20
            failureThreshold: 5
            periodSeconds: 60
            exec:
              command:              
                - sh
                - -c
                - |
                  CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR exec /entrypoint \
                  airflow jobs check --job-type SchedulerJob --local
          startupProbe:
            timeoutSeconds: 20
            failureThreshold: 6
            periodSeconds: 10
            exec:
              command:              
                - sh
                - -c
                - |
                  CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR exec /entrypoint \
                  airflow jobs check --job-type SchedulerJob --local
          resources:
            {}
          volumeMounts:
            - name: config
              mountPath: /opt/airflow/pod_templates/pod_template_file.yaml
              subPath: pod_template_file.yaml
              readOnly: true
            - name: logs
              mountPath: "/opt/airflow/logs"
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
            - name: config
              mountPath: "/opt/airflow/config/airflow_local_settings.py"
              subPath: airflow_local_settings.py
              readOnly: true
            - name: dags
              mountPath: /opt/airflow/dags
              readOnly: False
        - name: scheduler-log-groomer
          resources:
            {}
          image: apache/airflow:2.7.1
          imagePullPolicy: IfNotPresent
          securityContext: 
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
          args:
            - bash
            - /clean-logs
          env:
            - name: AIRFLOW__LOG_RETENTION_DAYS
              value: "15"
          volumeMounts:
            - name: logs
              mountPath: "/opt/airflow/logs"
      volumes:
        - name: config
          configMap:
            name: airflow-config
        - name: dags
          persistentVolumeClaim:
            claimName: airflow-dags
        - name: logs
          emptyDir: {}
---
# Source: airflow/templates/statsd/statsd-deployment.yaml
################################
## Airflow StatsD Deployment
#################################
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-statsd
  labels:
    tier: airflow
    component: statsd
    release: airflow
    chart: "airflow-1.11.0"
    heritage: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      tier: airflow
      component: statsd
      release: airflow
  template:
    metadata:
      labels:
        tier: airflow
        component: statsd
        release: airflow
    spec:
      nodeSelector:
        {}
      affinity:
        {}
      tolerations:
        []
      topologySpreadConstraints:
        []
      serviceAccountName: airflow-statsd
      securityContext: 
        runAsUser: 65534
      restartPolicy: Always
      containers:
        - name: statsd
          image: quay.io/prometheus/statsd-exporter:v0.22.8
          imagePullPolicy: IfNotPresent
          securityContext: 
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
          args: 
            - --statsd.mapping-config=/etc/statsd-exporter/mappings.yml
          resources:
            {}
          ports:
            - name: statsd-ingest
              protocol: UDP
              containerPort: 9125
            - name: statsd-scrape
              containerPort: 9102
          livenessProbe:
            httpGet:
              path: /metrics
              port: 9102
            initialDelaySeconds: 10
            periodSeconds: 10
            timeoutSeconds: 5
          readinessProbe:
            httpGet:
              path: /metrics
              port: 9102
            initialDelaySeconds: 10
            periodSeconds: 10
            timeoutSeconds: 5
          volumeMounts:
            - name: config
              mountPath: /etc/statsd-exporter/mappings.yml
              subPath: mappings.yml
      volumes:
        - name: config
          configMap:
            name: airflow-statsd
---
# Source: airflow/templates/webserver/webserver-deployment.yaml
################################
## Airflow Webserver Deployment
#################################
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-webserver
  labels:
    tier: airflow
    component: webserver
    release: airflow
    chart: "airflow-1.11.0"
    heritage: Helm
spec:
  replicas: 1
  strategy:
    # Here we define the rolling update strategy
    # - maxSurge define how many pod we can add at a time
    # - maxUnavailable define how many pod can be unavailable
    #   during the rolling update
    # Setting maxUnavailable to 0 would make sure we have the appropriate
    # capacity during the rolling update.
    # You can also use percentage based value instead of integer.
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      tier: airflow
      component: webserver
      release: airflow
  template:
    metadata:
      labels:
        tier: airflow
        component: webserver
        release: airflow
      annotations:
        checksum/metadata-secret: 1527346545415bf13f4c9ad69470086eb90d854f2b83594d78ec1badb5e13eb0
        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688
        checksum/webserver-secret-key: 470eb9e6276ce48138c00370a73e84a15f6ab18ed04d8b31505341401810836f
        checksum/airflow-config: 2bb0efc29b918ce453fdfc4eaa785e4c824f3f3b8284164228bbe9f76812a650
        checksum/webserver-config: 2f3fdfd294a37094d2abee43b2b09888a5c195ee03414996bf99a4681658af94
        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8
        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827
    spec:
      serviceAccountName: airflow-webserver
      nodeSelector:
        {}
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  component: webserver
              topologyKey: kubernetes.io/hostname
            weight: 100
      tolerations:
        []
      topologySpreadConstraints:
        []
      restartPolicy: Always
      securityContext: 
        runAsUser: 50000
        fsGroup: 0
      initContainers:
        - name: wait-for-airflow-migrations
          resources:
            {}
          image: apache/airflow:2.7.1
          imagePullPolicy: IfNotPresent
          securityContext: 
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
          volumeMounts:
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
            - name: config
              mountPath: "/opt/airflow/config/airflow_local_settings.py"
              subPath: airflow_local_settings.py
              readOnly: true
          args:          
            - airflow
            - db
            - check-migrations
            - --migration-wait-timeout=60
          envFrom:          
            []
          env:          
            # Dynamically created environment variables
            - name: OPENLINEAGE_NAMESPACE
              value: "airflow"
            # Dynamically created secret envs
            # Extra env          
            # Hard Coded Airflow Envs
            - name: AIRFLOW__CORE__FERNET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-fernet-key
                  key: fernet-key
            # For Airflow <2.3, backward compatibility; moved to [database] in 2.3
            - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW_CONN_AIRFLOW_DB
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW__WEBSERVER__SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-webserver-secret-key
                  key: webserver-secret-key
            - name: AIRFLOW__CELERY__BROKER_URL
              valueFrom:
                secretKeyRef:
                  name: airflow-broker-url
                  key: connection
      containers:
        - name: webserver
          image: apache/airflow:2.7.1
          imagePullPolicy: IfNotPresent
          securityContext: 
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
          args:
            - bash
            - -c
            - exec airflow webserver
          resources:
            {}
          volumeMounts:
            - name: config
              mountPath: /opt/airflow/pod_templates/pod_template_file.yaml
              subPath: pod_template_file.yaml
              readOnly: true
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
            - name: config
              mountPath: "/opt/airflow/config/airflow_local_settings.py"
              subPath: airflow_local_settings.py
              readOnly: true
          ports:
            - name: airflow-ui
              containerPort: 8080
          livenessProbe:
            httpGet:
              path: /health
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 15
            timeoutSeconds: 5
            failureThreshold: 5
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /health
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 15
            timeoutSeconds: 5
            failureThreshold: 5
            periodSeconds: 10
          startupProbe:
            httpGet:
              path: /health
              port: 8080
              scheme: HTTP
            timeoutSeconds: 20
            failureThreshold: 6
            periodSeconds: 10
          envFrom:          
            []
          env:          
            # Dynamically created environment variables
            - name: OPENLINEAGE_NAMESPACE
              value: "airflow"
            # Dynamically created secret envs
            # Extra env          
            # Hard Coded Airflow Envs
            - name: AIRFLOW__CORE__FERNET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-fernet-key
                  key: fernet-key
            # For Airflow <2.3, backward compatibility; moved to [database] in 2.3
            - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW_CONN_AIRFLOW_DB
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW__WEBSERVER__SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-webserver-secret-key
                  key: webserver-secret-key
            - name: AIRFLOW__CELERY__BROKER_URL
              valueFrom:
                secretKeyRef:
                  name: airflow-broker-url
                  key: connection          
      volumes:
        - name: config
          configMap:
            name: airflow-config
---
# Source: airflow/charts/postgresql/templates/primary/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: airflow-postgresql
  namespace: "airflow"
  labels:
    app.kubernetes.io/instance: airflow
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.10.0
    app.kubernetes.io/component: primary
spec:
  replicas: 1
  serviceName: airflow-postgresql-hl
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/instance: airflow
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/component: primary
  template:
    metadata:
      name: airflow-postgresql
      labels:
        app.kubernetes.io/instance: airflow
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: postgresql
        helm.sh/chart: postgresql-12.10.0
        app.kubernetes.io/component: primary
    spec:
      serviceAccountName: default
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: airflow
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/component: primary
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      hostNetwork: false
      hostIPC: false
      containers:
        - name: postgresql
          image: docker.io/bitnami/postgresql:11
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            runAsGroup: 0
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            # Authentication
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: airflow-postgresql
                  key: postgres-password
            # Replication
            # Initdb
            # Standby
            # LDAP
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            # TLS
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            # Audit
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            # Others
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "postgres" -h 127.0.0.1 -p 5432
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  exec pg_isready -U "postgres" -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
          resources:
            limits: {}
            requests:
              cpu: 250m
              memory: 256Mi
          volumeMounts:
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: airflow/templates/redis/redis-statefulset.yaml
################################
## Airflow Redis StatefulSet
#################################
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: airflow-redis
  labels:
    tier: airflow
    component: redis
    release: airflow
    chart: "airflow-1.11.0"
    heritage: Helm
spec:
  serviceName: airflow-redis
  selector:
    matchLabels:
      tier: airflow
      component: redis
      release: airflow
  template:
    metadata:
      labels:
        tier: airflow
        component: redis
        release: airflow
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
    spec:
      nodeSelector:
        {}
      affinity:
        {}
      tolerations:
        []
      topologySpreadConstraints:
        []
      serviceAccountName: airflow-redis
      securityContext: 
        runAsUser: 0
      containers:
        - name: redis
          image: redis:7-bullseye
          imagePullPolicy: IfNotPresent
          securityContext: 
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
          command: ["/bin/sh"]
          resources:
            {}
          args: ["-c", "redis-server --requirepass ${REDIS_PASSWORD}"]
          ports:
            - name: redis-db
              containerPort: 6379
          volumeMounts:
            - name: redis-db
              mountPath: /data
          env:
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: airflow-redis-password
                  key: password
  volumeClaimTemplates:
    - metadata:
        name: redis-db
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 1Gi
---
# Source: airflow/templates/triggerer/triggerer-deployment.yaml
################################
## Airflow Triggerer Deployment
#################################
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: airflow-triggerer
  labels:
    tier: airflow
    component: triggerer
    release: airflow
    chart: "airflow-1.11.0"
    heritage: Helm
spec:
  serviceName: airflow-triggerer
  replicas: 1
  selector:
    matchLabels:
      tier: airflow
      component: triggerer
      release: airflow
  template:
    metadata:
      labels:
        tier: airflow
        component: triggerer
        release: airflow
      annotations:
        checksum/metadata-secret: 1527346545415bf13f4c9ad69470086eb90d854f2b83594d78ec1badb5e13eb0
        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688
        checksum/airflow-config: 2bb0efc29b918ce453fdfc4eaa785e4c824f3f3b8284164228bbe9f76812a650
        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8
        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827
        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
    spec:
      nodeSelector:
        {}
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  component: triggerer
              topologyKey: kubernetes.io/hostname
            weight: 100
      tolerations:
        []
      topologySpreadConstraints:
        []
      terminationGracePeriodSeconds: 60
      restartPolicy: Always
      serviceAccountName: airflow-triggerer
      securityContext: 
        runAsUser: 50000
        fsGroup: 0
      initContainers:
        - name: wait-for-airflow-migrations
          resources:
            {}
          image: apache/airflow:2.7.1
          imagePullPolicy: IfNotPresent
          securityContext: 
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
          volumeMounts:
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
            - name: config
              mountPath: "/opt/airflow/config/airflow_local_settings.py"
              subPath: airflow_local_settings.py
              readOnly: true
          args:          
            - airflow
            - db
            - check-migrations
            - --migration-wait-timeout=60
          envFrom:          
            []
          env:          
            # Dynamically created environment variables
            - name: OPENLINEAGE_NAMESPACE
              value: "airflow"
            # Dynamically created secret envs
            # Extra env          
            # Hard Coded Airflow Envs
            - name: AIRFLOW__CORE__FERNET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-fernet-key
                  key: fernet-key
            # For Airflow <2.3, backward compatibility; moved to [database] in 2.3
            - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW_CONN_AIRFLOW_DB
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW__WEBSERVER__SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-webserver-secret-key
                  key: webserver-secret-key
            - name: AIRFLOW__CELERY__BROKER_URL
              valueFrom:
                secretKeyRef:
                  name: airflow-broker-url
                  key: connection
      containers:
        - name: triggerer
          image: apache/airflow:2.7.1
          imagePullPolicy: IfNotPresent
          securityContext: 
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
          args: 
            - bash
            - -c
            - exec airflow triggerer
          resources:
            {}
          volumeMounts:
            - name: logs
              mountPath: "/opt/airflow/logs"
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
            - name: config
              mountPath: "/opt/airflow/config/airflow_local_settings.py"
              subPath: airflow_local_settings.py
              readOnly: true
            - name: dags
              mountPath: /opt/airflow/dags
              readOnly: False
          envFrom:          
            []
          env:          
            # Dynamically created environment variables
            - name: OPENLINEAGE_NAMESPACE
              value: "airflow"
            # Dynamically created secret envs
            # Extra env          
            # Hard Coded Airflow Envs
            - name: AIRFLOW__CORE__FERNET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-fernet-key
                  key: fernet-key
            # For Airflow <2.3, backward compatibility; moved to [database] in 2.3
            - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW_CONN_AIRFLOW_DB
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW__WEBSERVER__SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-webserver-secret-key
                  key: webserver-secret-key
            - name: AIRFLOW__CELERY__BROKER_URL
              valueFrom:
                secretKeyRef:
                  name: airflow-broker-url
                  key: connection
          
          livenessProbe:
            initialDelaySeconds: 10
            timeoutSeconds: 20
            failureThreshold: 5
            periodSeconds: 60
            exec:
              command:              
                - sh
                - -c
                - |
                  CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR exec /entrypoint \
                  airflow jobs check --job-type TriggererJob --local
          ports:
            - name: triggerer-logs
              containerPort: 8794
        - name: triggerer-log-groomer
          resources:
            {}
          image: apache/airflow:2.7.1
          imagePullPolicy: IfNotPresent
          securityContext: 
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
          args:
            - bash
            - /clean-logs
          env:
            - name: AIRFLOW__LOG_RETENTION_DAYS
              value: "15"
          volumeMounts:
            - name: logs
              mountPath: "/opt/airflow/logs"
      volumes:
        - name: config
          configMap:
            name: airflow-config
        - name: dags
          persistentVolumeClaim:
            claimName: airflow-dags
  volumeClaimTemplates:
    - metadata:
        name: logs
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 100Gi
---
# Source: airflow/templates/workers/worker-deployment.yaml
################################
## Airflow Worker Deployment
#################################
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: airflow-worker
  labels:
    tier: airflow
    component: worker
    release: airflow
    chart: "airflow-1.11.0"
    heritage: Helm
spec:
  serviceName: airflow-worker
  replicas: 1
  selector:
    matchLabels:
      tier: airflow
      component: worker
      release: airflow
  template:
    metadata:
      labels:
        tier: airflow
        component: worker
        release: airflow
      annotations:
        checksum/metadata-secret: 1527346545415bf13f4c9ad69470086eb90d854f2b83594d78ec1badb5e13eb0
        checksum/result-backend-secret: 98a68f230007cfa8f5d3792e1aff843a76b0686409e4a46ab2f092f6865a1b71
        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688
        checksum/webserver-secret-key: 4f7651f285e69add73cdc7f5755a05938cb6ff49e04de7d5017c128c0231c6f4
        checksum/kerberos-keytab: 80979996aa3c1f48c95dfbe9bb27191e71f12442a08c0ed834413da9d430fd0e
        checksum/airflow-config: 2bb0efc29b918ce453fdfc4eaa785e4c824f3f3b8284164228bbe9f76812a650
        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8
        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827
        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
    spec:
      nodeSelector:
        {}
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  component: worker
              topologyKey: kubernetes.io/hostname
            weight: 100
      tolerations:
        []
      topologySpreadConstraints:
        []
      terminationGracePeriodSeconds: 600
      restartPolicy: Always
      serviceAccountName: airflow-worker
      securityContext: 
        runAsUser: 50000
        fsGroup: 0
      initContainers:
        - name: wait-for-airflow-migrations
          resources:
            {}
          image: apache/airflow:2.7.1
          imagePullPolicy: IfNotPresent
          securityContext: 
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
          volumeMounts:
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
            - name: config
              mountPath: "/opt/airflow/config/airflow_local_settings.py"
              subPath: airflow_local_settings.py
              readOnly: true
          args:          
            - airflow
            - db
            - check-migrations
            - --migration-wait-timeout=60
          envFrom:          
            []
          env:          
            # Dynamically created environment variables
            - name: OPENLINEAGE_NAMESPACE
              value: "airflow"
            # Dynamically created secret envs
            # Extra env          
            # Hard Coded Airflow Envs
            - name: AIRFLOW__CORE__FERNET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-fernet-key
                  key: fernet-key
            # For Airflow <2.3, backward compatibility; moved to [database] in 2.3
            - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW_CONN_AIRFLOW_DB
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW__WEBSERVER__SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-webserver-secret-key
                  key: webserver-secret-key
            - name: AIRFLOW__CELERY__BROKER_URL
              valueFrom:
                secretKeyRef:
                  name: airflow-broker-url
                  key: connection
      containers:
        - name: worker
          image: apache/airflow:2.7.1
          imagePullPolicy: IfNotPresent
          securityContext: 
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
          args: 
            - bash
            - -c
            - |-
              exec \
              airflow celery worker
          resources:
            {}
          livenessProbe:
            initialDelaySeconds: 10
            timeoutSeconds: 20
            failureThreshold: 5
            periodSeconds: 60
            exec:
              command:
                - sh
                - -c
                - CONNECTION_CHECK_MAX_COUNT=0 exec /entrypoint python -m celery --app airflow.providers.celery.executors.celery_executor.app inspect ping -d celery@$(hostname)
          ports:
            - name: worker-logs
              containerPort: 8793
          volumeMounts:
            - name: logs
              mountPath: "/opt/airflow/logs"
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
            - name: config
              mountPath: "/opt/airflow/config/airflow_local_settings.py"
              subPath: airflow_local_settings.py
              readOnly: true
            - name: dags
              mountPath: /opt/airflow/dags
              readOnly: False
          envFrom:          
            []
          env:
            # Only signal the main process, not the process group, to make Warm Shutdown work properly
            - name: DUMB_INIT_SETSID
              value: "0"          
            # Dynamically created environment variables
            - name: OPENLINEAGE_NAMESPACE
              value: "airflow"
            # Dynamically created secret envs
            # Extra env          
            # Hard Coded Airflow Envs
            - name: AIRFLOW__CORE__FERNET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-fernet-key
                  key: fernet-key
            # For Airflow <2.3, backward compatibility; moved to [database] in 2.3
            - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW_CONN_AIRFLOW_DB
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW__WEBSERVER__SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-webserver-secret-key
                  key: webserver-secret-key
            - name: AIRFLOW__CELERY__BROKER_URL
              valueFrom:
                secretKeyRef:
                  name: airflow-broker-url
                  key: connection          
        - name: worker-log-groomer
          image: apache/airflow:2.7.1
          imagePullPolicy: IfNotPresent
          securityContext: 
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
          args: 
            - bash
            - /clean-logs
          env:
            - name: AIRFLOW__LOG_RETENTION_DAYS
              value: "15"
          resources:
            {}
          volumeMounts:
            - name: logs
              mountPath: "/opt/airflow/logs"
      volumes:
        - name: config
          configMap:
            name: airflow-config
        - name: dags
          persistentVolumeClaim:
            claimName: airflow-dags
  volumeClaimTemplates:
    - metadata:
        name: logs
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 100Gi
---
# Source: airflow/templates/cleanup/cleanup-cronjob.yaml
################################
## Airflow Cleanup Pods CronJob
#################################
---
# Source: airflow/templates/cleanup/cleanup-serviceaccount.yaml
################################
## Airflow Cleanup ServiceAccount
#################################
---
# Source: airflow/templates/configmaps/extra-configmaps.yaml
####################################################
## Extra ConfigMaps provisioned via the chart values
####################################################
---
# Source: airflow/templates/configmaps/webserver-configmap.yaml
################################
## Airflow ConfigMap
#################################
---
# Source: airflow/templates/dag-processor/dag-processor-deployment.yaml
################################
## Airflow Dag Processor Deployment
#################################
---
# Source: airflow/templates/dag-processor/dag-processor-serviceaccount.yaml
################################
## Airflow Dag Processor ServiceAccount
#################################
---
# Source: airflow/templates/dags-persistent-volume-claim.yaml
######################################
## Airflow DAGs PersistentVolumeClaim
######################################
---
# Source: airflow/templates/flower/flower-deployment.yaml
################################
## Airflow Flower Deployment
#################################
---
# Source: airflow/templates/flower/flower-ingress.yaml
################################
## Airflow Flower Ingress
#################################
---
# Source: airflow/templates/flower/flower-networkpolicy.yaml
################################
## Airflow Flower NetworkPolicy
#################################
---
# Source: airflow/templates/flower/flower-service.yaml
################################
## Airflow Flower Service Component
#################################
---
# Source: airflow/templates/flower/flower-serviceaccount.yaml
######################################
## Airflow Flower ServiceAccount
######################################
---
# Source: airflow/templates/limitrange.yaml
################################
## Airflow Namespace LimitRange
#################################
---
# Source: airflow/templates/logs-persistent-volume-claim.yaml
######################################
## Airflow LOGs PersistentVolumeClaim
######################################
---
# Source: airflow/templates/pgbouncer/pgbouncer-deployment.yaml
################################
## Airflow Pgbouncer Deployment
#################################
---
# Source: airflow/templates/pgbouncer/pgbouncer-networkpolicy.yaml
################################
## Pgbouncer NetworkPolicy
#################################
---
# Source: airflow/templates/pgbouncer/pgbouncer-poddisruptionbudget.yaml
################################
## Pgbouncer PodDisruptionBudget
#################################
---
# Source: airflow/templates/pgbouncer/pgbouncer-service.yaml
################################
## Airflow Pgbouncer Service
#################################
---
# Source: airflow/templates/pgbouncer/pgbouncer-serviceaccount.yaml
######################################
## Airflow Pgbouncer ServiceAccount
######################################
---
# Source: airflow/templates/priorityclasses/priority-classes.yaml
#################################################
## Priority classes provisioned via the chart values
#################################################
---
# Source: airflow/templates/rbac/pod-cleanup-role.yaml
################################
## Airflow Cleanup Role
#################################
---
# Source: airflow/templates/rbac/pod-cleanup-rolebinding.yaml
################################
## Airflow Cleanup Role Binding
#################################
---
# Source: airflow/templates/rbac/security-context-constraint-rolebinding.yaml
################################
## Airflow SCC Role Binding
#################################
---
# Source: airflow/templates/redis/redis-networkpolicy.yaml
################################
## Airflow Redis NetworkPolicy
#################################
---
# Source: airflow/templates/resourcequota.yaml
################################
## Airflow Namespace ResourceQuota
#################################
---
# Source: airflow/templates/scheduler/scheduler-networkpolicy.yaml
################################
## Airflow Scheduler NetworkPolicy
#################################
---
# Source: airflow/templates/scheduler/scheduler-poddisruptionbudget.yaml
################################
## Airflow Scheduler PodDisruptionBudget
#################################
---
# Source: airflow/templates/scheduler/scheduler-service.yaml
################################
## Airflow Scheduler Service
#################################
---
# Source: airflow/templates/secrets/elasticsearch-secret.yaml
################################
## Elasticsearch Secret
#################################
---
# Source: airflow/templates/secrets/extra-secrets.yaml
#################################################
## Extra Secrets provisioned via the chart values
#################################################
---
# Source: airflow/templates/secrets/flower-secret.yaml
################################
## Flower Secret
#################################
---
# Source: airflow/templates/secrets/kerberos-keytab-secret.yaml
################################
## Kerberos Secret
#################################
---
# Source: airflow/templates/secrets/pgbouncer-certificates-secret.yaml
################################
## Pgbouncer Certificate Secret
#################################
---
# Source: airflow/templates/secrets/pgbouncer-config-secret.yaml
################################
## Pgbouncer Config Secret
#################################
---
# Source: airflow/templates/secrets/pgbouncer-stats-secret.yaml
################################
## Pgbouncer Stats Secret
#################################
---
# Source: airflow/templates/secrets/registry-secret.yaml
################################
## Registry Secret
#################################
---
# Source: airflow/templates/secrets/result-backend-connection-secret.yaml
################################
## Airflow Result Backend Secret
#################################
---
# Source: airflow/templates/statsd/statsd-networkpolicy.yaml
################################
## Airflow StatsD NetworkPolicy
#################################
---
# Source: airflow/templates/triggerer/triggerer-kedaautoscaler.yaml
################################
## Airflow Triggerer KEDA Scaler
#################################
---
# Source: airflow/templates/triggerer/triggerer-networkpolicy.yaml
##################################
## Airflow triggerer NetworkPolicy
##################################
---
# Source: airflow/templates/webserver/webserver-ingress.yaml
################################
## Airflow Webserver Ingress
#################################
---
# Source: airflow/templates/webserver/webserver-networkpolicy.yaml
################################
## Airflow Webserver NetworkPolicy
#################################
---
# Source: airflow/templates/webserver/webserver-poddisruptionbudget.yaml
################################
## Airflow Webserver PodDisruptionBudget
#################################
---
# Source: airflow/templates/workers/worker-kedaautoscaler.yaml
################################
## Airflow Worker KEDA Scaler
#################################
---
# Source: airflow/templates/workers/worker-networkpolicy.yaml
################################
## Airflow Worker NetworkPolicy
#################################

NOTES:
Thank you for installing Apache Airflow 2.7.1!

Your release is named airflow.
You can now access your dashboard(s) by executing the following command(s) and visiting the corresponding port at localhost in your browser:

Airflow Webserver:     kubectl port-forward svc/airflow-webserver 8080:8080 --namespace airflow
Default Webserver (Airflow UI) Login credentials:
    username: admin
    password: admin
Default Postgres connection credentials:
    username: postgres
    password: postgres
    port: 5432

You can get Fernet Key value by running the following:

    echo Fernet Key: $(kubectl get secret --namespace airflow airflow-fernet-key -o jsonpath="{.data.fernet-key}" | base64 --decode)

###########################################################
#  WARNING: You should set a static webserver secret key  #
###########################################################

You are using a dynamically generated webserver secret key, which can lead to
unnecessary restarts of your Airflow components.

Information on how to set a static webserver secret key can be found here:
https://airflow.apache.org/docs/helm-chart/stable/production-guide.html#webserver-secret-key
